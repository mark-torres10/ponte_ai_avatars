# 2025-08-21

10:10am: Tinkered around with ElevenLabs and then some video generation.

Looks like it only supports 14 second clips for now? So we'd have to stitch it together in post-processing I suppose?
"""
TITLE: Virtual Keynote Intro — Athlete Avatar (14s, 1080p, 16:9)

DURATION & FORMAT:
- Duration ~14 seconds; single continuous shot with subtle camera motion.
- Resolution 1920×1080; Aspect ratio 16:9 (widescreen). Target for stage screens and YouTube; crop-able for 9:16 later.

SUBJECT & CONTEXT:
- Primary subject: photorealistic avatar of a professional athlete (use provided base image). Age mid-20s to mid-30s, confident, charismatic, warm smile.
- Setting: modern conference stage with large LED backdrop; abstract geometric pattern inspired by athletic aesthetics (monochrome with soft neutral accents). 
- IMPORTANT BRAND NOTE: No real brand logos or trademarked three-stripe iconography. Use generic abstract stripes and geometric motifs only.

ACTION (VISUAL PERFORMANCE):
- Natural head gestures, subtle brow and eye engagement, occasional light hand emphasis within frame.
- Lip movements synchronized to external voiceover (do NOT generate synthetic speech). Maintain relaxed, authentic presence; no exaggerated smiling.

CAMERA:
- Locked tripod feel with a gentle 5–7% push-in over the full clip (very slow dolly-in).
- Eye-level framing. Start medium shot (mid-torso up), end slightly tighter (chest up).
- Minimal parallax from animated LED backdrop (slow looping abstract motion).

COMPOSITION:
- Subject centered, rule-of-thirds-friendly headroom.
- Depth: softly defocused audience area; crisp subject; backdrop readable but not distracting.

LIGHTING & AMBIENCE:
- Soft, flattering key light; subtle back rim to separate subject from background; stage wash practicals.
- Clean color temperature (around 5000–5600K). Avoid harsh contrast or club-like lighting.
- No lens flares, no strobing.

WARDROBE & STYLING:
- Smart-casual sport aesthetic (e.g., tailored jacket over performance tee). Neutral palette to avoid brand conflicts.

AUDIO DIRECTION:
- MUTE in-generation audio. Expect external VO track from ElevenLabs. Ensure mouth shapes match natural English phonemes. Maintain room-tone visual realism only (no crowd SFX).

TIMING BEATS:
[00:00.000 --> 00:00.840]  Hello, everyone.
[00:00.840 --> 00:05.520]  It is such an honor to be here with you at the 2025 Summit.
[00:05.520 --> 00:07.400]  Even though I can't be there in person,
[00:07.400 --> 00:10.880]  I'm absolutely thrilled to welcome you virtually.
[00:10.880 --> 00:14.120]  Today's event is proudly presented by Adidas.

STYLE/LOOK:
- Photoreal; keynote broadcast aesthetic; clean color grade; documentary-sharp details on face/hair/eyes; avoid hyper-saturation or plastic skin.
- Professional conference LUT; subtle vignette; smooth motion; no artificial “AI shimmer.”

TEXT/GRAPHICS:
- No on-screen text overlays or lower-thirds (voiceover carries all messaging). Backdrop remains abstract only.

NEGATIVE PROMPT (STRICT):
- No brand wordmarks or recognizable Adidas logos/three-stripe marks; no over-saturated colors; no harsh studio strobes; no warped hands/teeth; no mouth desync; no extra fingers; no exaggerated smiles; no distracting bokeh glitter; no glitching or flicker; no text overlays.

Produce a single-shot, photoreal keynote-intro of an athlete avatar delivering a 40s greeting on a modern stage. Subtle push-in, natural gestures, perfect lip-sync to supplied audio, abstract sponsor-themed backdrop without any real brand logos. Clean, premium, broadcast-ready output.
"""

Success here today looks like:
- Being able to generate an example asset with ElevenLabs + Higgsfield.
- Propose a first pass playbook for how to create, for example, a TikTok video, and then we can try it out and see how it looks.

10:19am: Oh, what if once I figure out a playbook, we can have some basic automations set up with n8n? That way, we can iterate very quickly. I've seen similar such playbooks before.

Looks like Blotato is a tool that's used? https://community.n8n.io/t/how-i-automated-all-my-social-media-posts-with-n8n-and-blotato/

I had ChatGPT do some research on how people use AI for content creation: https://chatgpt.com/c/68a72c97-1518-8328-bb35-6b5706ef4314

Blotato looks pretty good! I'll have to investigate that a little bit more: https://chatgpt.com/c/68a73903-c154-8327-80c6-0c6b66099fba

10:26am: first pass video looks great! Mouth still doesn't really align with the speaking, bleh, but we can likely postprocess this using Descript.

So, today I accomplished:
- Having an example case study:
 - Script (ChatGPT)
 - Audio (ElevenLabs)
 - Video V1 (Higgsfield/Veo3/HeyGen): HeyGen is great for audio/visual coherence (e.g., mouth is aligned with noise) but Higgsfield and Veo3 are great with one-shotting entire scenes.
 - Postprocessing (Descript)

I think this is a reasonable first pass! I'll show what I have and then the proposed setup, and I'll do this via Loom. I'll also upload to OneDrive.

10:55am: I'll try HeyGen real quick and see how that syncing does.

11:51am: HeyGen works pretty well, and coherence for speaking + mouth is really good! Passing that into Descript now.

5:03pm: Created a first pass of an SOP.

I think let's create some simple workflows first, just something imperfect and a V1 in order to start something, and then as we create content and see how it is, we refine the steps. But let's at least get a V1 going. I think this is likely where my knowledge of systems and automation is best applied. I don't know what makes a TikTok good, but I can help create a repeatable and reliable way to push TikTok content out there, and then we can iterate over time.

I should also ask the PonteAI folks how likely they are to want to extend past the initial 8-week plan. I'll present my MVP proposal first though, and then ask them "assuming we can hit all of this, what is the likelihood of us continuing to work together" as I can frame it as "I can either curate this assuming that there will be a hand-off at some point or I can prioritize development assuming continuity past the initial 8 weeks".

TODO: check the ChatGPT thread in https://chatgpt.com/g/g-p-68a624cf391881918e7293fafa885f64-client-ponteai/c/68a79660-1310-8325-b27a-bfd4af96912d, lots of good thoughts here.
